{
 "metadata": {
  "name": "",
  "signature": "sha256:77e4c9a7e6b927dc92aa9a2741ab8e2cb9debb0807fcd9dc358a09a7f9b68401"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#given corpus\n",
      "corpus = [\"this is doc1 ML this is doc1 ML\", \"is this right ML right\", \"yes seems great one ML great right\"]\n",
      "corpus = [\"this is dog this is cat\", \"this is cat\", \"that is different\", \"he is different\", \"they are happy\"]\n",
      "\n",
      "query = [\"this is query\"]\n",
      "\n",
      "#bag of words i.e. SET\n",
      "bag_of_words = []\n",
      "\n",
      "#stop words\n",
      "stop_words = [\"this\", \"is\", \"yes\", \"seems\"]\n",
      "#read each doc, tokenize and put it in bag of words\n",
      "for d in corpus:\n",
      "    for w in d.split():\n",
      "        #if w not in stop_words:\n",
      "            bag_of_words.append(w)\n",
      "\n",
      "#make a set i.e. unique list of words i.e. final bag of words\n",
      "bag_of_words = list(set(bag_of_words))\n",
      "print bag_of_words\n",
      "\n",
      "#make feature => index  map, which gives the index of value of the feature in vector\n",
      "dimensions_index_map = {}\n",
      "for i, w in enumerate(bag_of_words):\n",
      "    dimensions_index_map[w] = i\n",
      "#print dimensions_index_map\n",
      "\n",
      "#make document vectors corpus\n",
      "vector_corpus = []\n",
      "#for d in query:\n",
      "for d in corpus:\n",
      "    v1 = [0] * len(bag_of_words)\n",
      "    tokens = d.split()\n",
      "    for w in bag_of_words:\n",
      "        cnt = tokens.count(w)\n",
      "        v1[dimensions_index_map[w]] = cnt\n",
      "    vector_corpus.append(v1)\n",
      "        \n",
      "print \"BAG OF WORDS MODEL VECTORIZED DOCS\\n\", vector_corpus\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "['different', 'that', 'this', 'is', 'dog', 'cat', 'are', 'they', 'happy', 'he']\n",
        "[[0, 0, 2, 2, 1, 1, 0, 0, 0, 0], [0, 0, 1, 1, 0, 1, 0, 0, 0, 0], [1, 1, 0, 1, 0, 0, 0, 0, 0, 0], [1, 0, 0, 1, 0, 0, 0, 0, 0, 1], [0, 0, 0, 0, 0, 0, 1, 1, 1, 0]]\n"
       ]
      }
     ],
     "prompt_number": 30
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#HAC POC\n",
      "\n",
      "\n",
      "#clusters hashmap\n",
      "print \"BAG OF WORDS MODEL VECTORIZED DOCS\\n\"\n",
      "clusters = {}\n",
      "i = 1\n",
      "for v in vector_corpus:\n",
      "    print v\n",
      "    clusters['d' + str(i)] = v\n",
      "    i += 1\n",
      "\n",
      "print \"\\n\\INITIAL CLUSTERS \\n\", clusters, \"\\n\"\n",
      "print \"-\"*50, \"\\n\"\n",
      "\n",
      "#COSINE SIMILARITY FUNCTION\n",
      "import numpy as np\n",
      "def cosine_sim(v1, v2):\n",
      "    a = np.array(v1)\n",
      "    b = np.array(v2)\n",
      "    c = np.dot(a, b)\n",
      "    sim = float(c) / (np.linalg.norm(a) * np.linalg.norm(b))\n",
      "    \n",
      "    return sim\n",
      "\n",
      "#temporary similarity hashmap\n",
      "temp = {}\n",
      "\n",
      "#cluster pair hashmap\n",
      "cluster_pair = {}\n",
      "itr = 1\n",
      "k = 1\n",
      "dendogram_root = ''\n",
      "while (len(clusters) != 1):\n",
      "    print \"ITERATION # \", itr, \"\\n\"\n",
      "    itr += 1\n",
      "#while (k):\n",
      "    temp = {}\n",
      "    for i in clusters.keys():\n",
      "        for j in clusters.keys():\n",
      "            i_c = j + \"-\" + i\n",
      "            #print i_c, temp\n",
      "            if i != j and i_c not in temp:\n",
      "                sim = cosine_sim(clusters[i], clusters[j])\n",
      "                temp[i + \"-\" + j] = sim\n",
      "                cluster_pair[i + \"-\" + j] = [i,j]\n",
      "                \n",
      "                \n",
      "\n",
      "    #print \"temp = \", temp, \" and cluster_pair = \", cluster_pair\n",
      "    #FIND MAX SIMILARITY PAIR and delete other pairs from cluster_pair\n",
      "\n",
      "    print \"temporary simialrity map \", temp, \"\\n\"\n",
      "    max_sim = 0\n",
      "    pair = ''\n",
      "    for c in temp:\n",
      "        if temp[c] >= max_sim:\n",
      "            max_sim = temp[c]\n",
      "            pair = c\n",
      "        else:\n",
      "            del cluster_pair[c]  #delete the lower value entry from cluster_pair\n",
      "            \n",
      "      \n",
      "    #print \"cluster pair = \", cluster_pair\n",
      "    \n",
      "    print \"closer cluster = \", pair, \" using parts \", cluster_pair[pair][0], \" and \", cluster_pair[pair][1]\n",
      "    #ADD MAX-SIM PAIR TO CLUSTERS AS AVERAGE OF INDIVIDUAL VECTORS\n",
      "    clusters[pair] = (np.array(clusters[cluster_pair[pair][0]]) + np.array(clusters[cluster_pair[pair][1]])) / 2\n",
      "    \n",
      "    #DELETE INDIVIDUAL CLUSTERS FROM CLUSTERS HASHMAP\n",
      "    del clusters[cluster_pair[pair][0]]\n",
      "    del clusters[cluster_pair[pair][1]]\n",
      "        \n",
      "    print \"formed cluster = \", pair, \"\\nmodified clusters = \", clusters, \"\\n\"\n",
      "    k -= 1\n",
      "    print \"-\"*50, \"\\n\"\n",
      "    dendogram_root = pair\n",
      "\n",
      "print \"Final dendogram root = \", dendogram_root\n",
      "\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "BAG OF WORDS MODEL VECTORIZED DOCS\n",
        "\n",
        "[0, 0, 2, 2, 1, 1, 0, 0, 0, 0]\n",
        "[0, 0, 1, 1, 0, 1, 0, 0, 0, 0]\n",
        "[1, 1, 0, 1, 0, 0, 0, 0, 0, 0]\n",
        "[1, 0, 0, 1, 0, 0, 0, 0, 0, 1]\n",
        "[0, 0, 0, 0, 0, 0, 1, 1, 1, 0]\n",
        "\n",
        "\n",
        "INITAIL CLUSTERS \n",
        "{'d4': [1, 0, 0, 1, 0, 0, 0, 0, 0, 1], 'd5': [0, 0, 0, 0, 0, 0, 1, 1, 1, 0], 'd2': [0, 0, 1, 1, 0, 1, 0, 0, 0, 0], 'd3': [1, 1, 0, 1, 0, 0, 0, 0, 0, 0], 'd1': [0, 0, 2, 2, 1, 1, 0, 0, 0, 0]} \n",
        "\n",
        "-------------------------------------------------- \n",
        "\n",
        "ITERATION #  1 \n",
        "\n",
        "temporary simialrity map  {'d5-d1': 0.0, 'd3-d1': 0.36514837167011072, 'd2-d3': 0.33333333333333337, 'd2-d1': 0.9128709291752769, 'd4-d5': 0.0, 'd5-d3': 0.0, 'd5-d2': 0.0, 'd4-d2': 0.33333333333333337, 'd4-d3': 0.66666666666666674, 'd4-d1': 0.36514837167011072} \n",
        "\n",
        "closer cluster =  d2-d1  using parts  d2  and  d1\n",
        "formed cluster =  d2-d1 \n",
        "modified clusters =  {'d2-d1': array([0, 0, 1, 1, 0, 1, 0, 0, 0, 0]), 'd4': [1, 0, 0, 1, 0, 0, 0, 0, 0, 1], 'd5': [0, 0, 0, 0, 0, 0, 1, 1, 1, 0], 'd3': [1, 1, 0, 1, 0, 0, 0, 0, 0, 0]} \n",
        "\n",
        "-------------------------------------------------- \n",
        "\n",
        "ITERATION #  2 \n",
        "\n",
        "temporary simialrity map  {'d2-d1-d5': 0.0, 'd2-d1-d4': 0.33333333333333337, 'd2-d1-d3': 0.33333333333333337, 'd4-d5': 0.0, 'd5-d3': 0.0, 'd4-d3': 0.66666666666666674} \n",
        "\n",
        "closer cluster =  d4-d3  using parts  d4  and  d3\n",
        "formed cluster =  d4-d3 \n",
        "modified clusters =  {'d4-d3': array([1, 0, 0, 1, 0, 0, 0, 0, 0, 0]), 'd2-d1': array([0, 0, 1, 1, 0, 1, 0, 0, 0, 0]), 'd5': [0, 0, 0, 0, 0, 0, 1, 1, 1, 0]} \n",
        "\n",
        "-------------------------------------------------- \n",
        "\n",
        "ITERATION #  3 \n",
        "\n",
        "temporary simialrity map  {'d4-d3-d5': 0.0, 'd4-d3-d2-d1': 0.40824829046386296, 'd2-d1-d5': 0.0} \n",
        "\n",
        "closer cluster =  d4-d3-d2-d1  using parts  d4-d3  and  d2-d1\n",
        "formed cluster =  d4-d3-d2-d1 \n",
        "modified clusters =  {'d4-d3-d2-d1': array([0, 0, 0, 1, 0, 0, 0, 0, 0, 0]), 'd5': [0, 0, 0, 0, 0, 0, 1, 1, 1, 0]} \n",
        "\n",
        "-------------------------------------------------- \n",
        "\n",
        "ITERATION #  4 \n",
        "\n",
        "temporary simialrity map  {'d4-d3-d2-d1-d5': 0.0} \n",
        "\n",
        "closer cluster =  d4-d3-d2-d1-d5  using parts  d4-d3-d2-d1  and  d5\n",
        "formed cluster =  d4-d3-d2-d1-d5 \n",
        "modified clusters =  {'d4-d3-d2-d1-d5': array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0])} \n",
        "\n",
        "-------------------------------------------------- \n",
        "\n",
        "Final dendogram root =  d4-d3-d2-d1-d5\n"
       ]
      }
     ],
     "prompt_number": 73
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#test average of two vectors\n",
      "import numpy as np\n",
      "old_set = [[0, 1], [4, 5]]\n",
      "new_set = [[2, 7], [0, 1]]\n",
      "print (np.array(old_set) + np.array(new_set)) / 2\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "[[1 4]\n",
        " [2 3]]\n"
       ]
      }
     ],
     "prompt_number": 21
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}